{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNV7yLS9aHcqccTb7q7+Rgx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIPANJAN001/Dipanjanpatra/blob/master/PVx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B57RdFK_WG53",
        "outputId": "aeafcc1c-8056-4bdd-e074-a0ae95078518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Boruta in /usr/local/lib/python3.7/dist-packages (0.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from Boruta) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from Boruta) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from Boruta) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.17.1->Boruta) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.17.1->Boruta) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install Boruta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from boruta import BorutaPy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import concatenate\n",
        "from keras import Model\n",
        "from keras.layers import Input"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_excel(\"/content/pv_04.xlsx\")\n",
        "weather_input1=df.drop('power_normed',axis=1)\n",
        "weather_input=weather_input1.drop('time_idx',axis=1)\n",
        "solpow=df['power_normed']"
      ],
      "metadata": {
        "id": "yppt8YsWW7Q-"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestRegressor(random_state=1, n_estimators=1000, max_depth=5)\n",
        "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, random_state=1)\n",
        "boruta_selector.fit(np.array(weather_input), np.array(solpow)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27rOaZCAXZ8a",
        "outputId": "2f6cd8d9-1108-42df-a470-9bbf53558a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t49\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 100\n",
            "Confirmed: \t9\n",
            "Tentative: \t17\n",
            "Rejected: \t23\n",
            "Iteration: \t9 / 100\n",
            "Confirmed: \t9\n",
            "Tentative: \t17\n",
            "Rejected: \t23\n",
            "Iteration: \t10 / 100\n",
            "Confirmed: \t9\n",
            "Tentative: \t17\n",
            "Rejected: \t23\n",
            "Iteration: \t11 / 100\n",
            "Confirmed: \t9\n",
            "Tentative: \t17\n",
            "Rejected: \t23\n",
            "Iteration: \t12 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t16\n",
            "Rejected: \t23\n",
            "Iteration: \t13 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t16\n",
            "Rejected: \t23\n",
            "Iteration: \t14 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t16\n",
            "Rejected: \t23\n",
            "Iteration: \t15 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t16\n",
            "Rejected: \t23\n",
            "Iteration: \t16 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t15\n",
            "Rejected: \t23\n",
            "Iteration: \t17 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t15\n",
            "Rejected: \t23\n",
            "Iteration: \t18 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t15\n",
            "Rejected: \t23\n",
            "Iteration: \t19 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t14\n",
            "Rejected: \t23\n",
            "Iteration: \t20 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t14\n",
            "Rejected: \t23\n",
            "Iteration: \t21 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t14\n",
            "Rejected: \t23\n",
            "Iteration: \t22 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t12\n",
            "Rejected: \t23\n",
            "Iteration: \t23 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t12\n",
            "Rejected: \t23\n",
            "Iteration: \t24 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t12\n",
            "Rejected: \t23\n",
            "Iteration: \t25 / 100\n",
            "Confirmed: \t14\n",
            "Tentative: \t12\n",
            "Rejected: \t23\n",
            "Iteration: \t26 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t10\n",
            "Rejected: \t24\n",
            "Iteration: \t27 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t10\n",
            "Rejected: \t24\n",
            "Iteration: \t28 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t10\n",
            "Rejected: \t24\n",
            "Iteration: \t29 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t10\n",
            "Rejected: \t24\n",
            "Iteration: \t30 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t10\n",
            "Rejected: \t24\n",
            "Iteration: \t31 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t10\n",
            "Rejected: \t24\n",
            "Iteration: \t32 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t10\n",
            "Rejected: \t24\n",
            "Iteration: \t33 / 100\n",
            "Confirmed: \t15\n",
            "Tentative: \t10\n",
            "Rejected: \t24\n",
            "Iteration: \t34 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t9\n",
            "Rejected: \t24\n",
            "Iteration: \t35 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t9\n",
            "Rejected: \t24\n",
            "Iteration: \t36 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t9\n",
            "Rejected: \t24\n",
            "Iteration: \t37 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t9\n",
            "Rejected: \t24\n",
            "Iteration: \t38 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t9\n",
            "Rejected: \t24\n",
            "Iteration: \t39 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t9\n",
            "Rejected: \t24\n",
            "Iteration: \t40 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t9\n",
            "Rejected: \t24\n",
            "Iteration: \t41 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t9\n",
            "Rejected: \t24\n",
            "Iteration: \t42 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t9\n",
            "Rejected: \t24\n",
            "Iteration: \t43 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t9\n",
            "Rejected: \t24\n",
            "Iteration: \t44 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t9\n",
            "Rejected: \t24\n",
            "Iteration: \t45 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t9\n",
            "Rejected: \t24\n",
            "Iteration: \t46 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t9\n",
            "Rejected: \t24\n",
            "Iteration: \t47 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t9\n",
            "Rejected: \t24\n",
            "Iteration: \t48 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t9\n",
            "Rejected: \t24\n",
            "Iteration: \t49 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t9\n",
            "Rejected: \t24\n",
            "Iteration: \t50 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t9\n",
            "Rejected: \t24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_data_transform(x_data, y_data, num_steps):\n",
        "    \"\"\" Changes data to the format for LSTM training \n",
        "for sliding window approach \"\"\"\n",
        "    # Prepare the list for the transformed data\n",
        "    X, y = list(), list()\n",
        "    # Loop of the entire data set\n",
        "    for i in range(x_data.shape[0]):\n",
        "        # compute a new (sliding window) index\n",
        "        end_ix = i + num_steps\n",
        "        # if index is larger than the size of the dataset, we stop\n",
        "        if end_ix >= x_data.shape[0]:\n",
        "            break\n",
        "        # Get a sequence of data for x\n",
        "        seq_X = x_data[i:end_ix]\n",
        "        # Get only the last element of the sequency for y\n",
        "        seq_y = y_data[end_ix]\n",
        "        # Append the list with sequencies\n",
        "        X.append(seq_X)\n",
        "        y.append(seq_y)\n",
        "    # Make final arrays\n",
        "    x_array = np.array(X)\n",
        "    y_array = np.array(y)\n",
        "    return x_array, y_array"
      ],
      "metadata": {
        "id": "8haqeUkUXmPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_important_train = boruta_selector.transform(np.array(weather_input))\n",
        "num_steps = 3\n",
        "# training set\n",
        "(x_transformed_train,\n",
        " y_transformed_train) = lstm_data_transform(X_important_train,solpow , num_steps=num_steps)\n",
        "assert x_transformed_train.shape[0] == y_transformed_train.shape[0]\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_transformed_train,y_transformed_train,test_size=0.4, random_state=42,shuffle=False)\n",
        "#X_train_,X_val,y_train_,y_val=train_test_split(X_train,y_train,test_size=0.2, random_state=42,shuffle=False)"
      ],
      "metadata": {
        "id": "fR8k9YUoXp3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))"
      ],
      "metadata": {
        "id": "qNg60ZpBYKpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Bidirectional\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "4_CBuAx_cITk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model1(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe1_0 = Bidirectional(LSTM(32, activation='relu',return_sequences = True))(inputs1)#32\n",
        "    fe1_1 = Dropout(0.2)(fe1_0)\n",
        "    fe1_2 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(fe1_1)#16\n",
        "    fe1_3= Dropout(0.2)(fe1_2)\n",
        "    fe1_4=Bidirectional(LSTM(8, activation='relu'))(fe1_3)#8\n",
        "    out1_1=Dense(1, activation='linear')(fe1_4)\n",
        "    return Model(inputs1, out1_1)\n",
        "def get_model2(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe2_0 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(inputs1)#16,16,8\n",
        "    fe2_1 = Dropout(0.5)(fe2_0)\n",
        "    fe2_2 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(fe2_1)\n",
        "    fe2_3= Dropout(0.5)(fe2_2)\n",
        "    fe2_4=Bidirectional(LSTM(8, activation='relu'))(fe2_3)\n",
        "    out2_1=Dense(1, activation='linear')(fe2_4)\n",
        "    return Model(inputs1, out2_1)\n",
        "def get_model3(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe3_0 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(inputs1)#16,8,8\n",
        "    fe3_1 = Dropout(0.5)(fe3_0)\n",
        "    fe3_2 = Bidirectional(LSTM(8, activation='relu',return_sequences = True))(fe3_1)\n",
        "    fe3_3= Dropout(0.5)(fe3_2)\n",
        "    fe3_4=Bidirectional(LSTM(8, activation='relu'))(fe3_3)\n",
        "    out3_1=Dense(1, activation='linear')(fe3_4)\n",
        "    return Model(inputs1, out3_1)\n",
        "model1 = get_model1() \n",
        "model2 = get_model2() \n",
        "model3 = get_model3()\n",
        "y1 = model1(inputs1) \n",
        "y2 = model2(inputs1) \n",
        "y3 = model3(inputs1)\n",
        "outputs = layers.average([y1, y2, y3]) \n",
        "ensemble_model = Model(inputs=inputs1, outputs=outputs)\n",
        "ensemble_model.compile(optimizer='Adam',loss='mean_squared_error',metrics=['RootMeanSquaredError'])\n",
        "history=ensemble_model.fit(X_train, y_train, epochs = 200, batch_size = 64)"
      ],
      "metadata": {
        "id": "goWTvO-lb73P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_en_=ensemble_model.predict(X_test)\n",
        "plt.scatter(y_en_,y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rqm5Zz_nWILI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ = pd.DataFrame()\n",
        "df_['time']=[i for i in range(len(y_en_))]\n",
        "df_['Actual']=y_test\n",
        "df_['Predicted']=y_en_"
      ],
      "metadata": {
        "id": "h0GhbT99ThD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(df_['time'],df_['Actual'])\n",
        "plt.plot(df_['time'],df_['Predicted'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "57wAZEiMTnjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model1(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe1_0 = Bidirectional(LSTM(32, activation='relu',return_sequences = True))(inputs1)#32\n",
        "    fe1_1 = Dropout(0.2)(fe1_0)\n",
        "    fe1_2 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(fe1_1)#16\n",
        "    fe1_3= Dropout(0.2)(fe1_2)\n",
        "    fe1_4=Bidirectional(LSTM(8, activation='relu'))(fe1_3)#8\n",
        "    out1_1=Dense(1, activation='linear')(fe1_4)\n",
        "    return Model(inputs1, out1_1)\n",
        "def get_model2(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe2_0 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(inputs1)#16,16,8\n",
        "    fe2_1 = Dropout(0.5)(fe2_0)\n",
        "    fe2_2 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(fe2_1)\n",
        "    fe2_3= Dropout(0.5)(fe2_2)\n",
        "    fe2_4=Bidirectional(LSTM(8, activation='relu'))(fe2_3)\n",
        "    out2_1=Dense(1, activation='linear')(fe2_4)\n",
        "    return Model(inputs1, out2_1)\n",
        "def get_model3(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe3_0 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(inputs1)#16,8,8\n",
        "    fe3_1 = Dropout(0.5)(fe3_0)\n",
        "    fe3_2 = Bidirectional(LSTM(8, activation='relu',return_sequences = True))(fe3_1)\n",
        "    fe3_3= Dropout(0.5)(fe3_2)\n",
        "    fe3_4=Bidirectional(LSTM(8, activation='relu'))(fe3_3)\n",
        "    out3_1=Dense(1, activation='linear')(fe3_4)\n",
        "    return Model(inputs1, out3_1)\n",
        "model1 = get_model1() \n",
        "#model2 = get_model2() \n",
        "model3 = get_model3()\n",
        "y1 = model1(inputs1) \n",
        "#y2 = model2(inputs1) \n",
        "y3 = model3(inputs1)\n",
        "outputs = layers.average([y1,y3]) \n",
        "ensemble_model = Model(inputs=inputs1, outputs=outputs)\n",
        "ensemble_model.compile(optimizer='Adam',loss='mean_squared_error',metrics=['RootMeanSquaredError'])\n",
        "history=ensemble_model.fit(X_train, y_train, epochs = 200, batch_size = 64)"
      ],
      "metadata": {
        "id": "HEeIP_LxCPTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_en=ensemble_model.predict(X_test)\n",
        "plt.scatter(y_en,y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XyrZrQE6ddFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6m8nXs7WfiLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ = pd.DataFrame()"
      ],
      "metadata": {
        "id": "pY6nosyciZbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_['time']=[i for i in range(len(y_en))]\n",
        "df_['Actual']=y_test\n",
        "df_['Predicted']=y_en\n",
        "df_['Predicted1']=y_en_"
      ],
      "metadata": {
        "id": "bJn8ecqBiRTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df__= pd.DataFrame()"
      ],
      "metadata": {
        "id": "5OtXkrFnXlrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df__['time']=[i for i in range(len(solpow))]\n",
        "df__['power']=solpow"
      ],
      "metadata": {
        "id": "d-toXgEQXcTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "id": "Xc3lVlsSieTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig = make_subplots(rows=1, cols=1)\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=df_.reset_index()['time'], y=df_.reset_index()['Actual'],name='Actual generated solar power'),row=1,col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=df_.reset_index()['time'], y=df_.reset_index()['Predicted'],name='Predicted generated solar power LSTM '),row=1,col=1\n",
        ")\n",
        "fig.update_xaxes(title_text=\"Time\")\n",
        "fig.update_yaxes(title_text=\"SolarPower\")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "LDFQdC5HigYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(df_['time'],df_['Actual'])\n",
        "plt.plot(df_['time'],df_['Predicted'])\n",
        "plt.show()\n",
        "plt.plot(df_['time'],df_['Actual'])\n",
        "plt.plot(df_['time'],df_['Predicted1'])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jtbpsZffUdd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input"
      ],
      "metadata": {
        "id": "9_rTy4wYEs4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_inputs=weather_input.shape[1]"
      ],
      "metadata": {
        "id": "bGukXRzXExcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_shape= Input(shape=(n_inputs,))\n",
        "# encoder level 1\n",
        "encoder= Dense(n_inputs*2)(input_data_shape)\n",
        "encoder = BatchNormalization()(encoder)\n",
        "encoder= LeakyReLU()(encoder)\n",
        "# encoder level 2\n",
        "encoder= Dense(n_inputs)(encoder)\n",
        "encoder= BatchNormalization()(encoder)\n",
        "encoder= LeakyReLU()(encoder)\n",
        "# bottleneck\n",
        "#n_bottleneck = round(float(n_inputs) / 2.0)\n",
        "n_bottleneck = 20\n",
        "bottleneck = Dense(n_bottleneck)(encoder)\n",
        "# define decoder, level 1\n",
        "decoder = Dense(n_inputs)(bottleneck)\n",
        "decoder = BatchNormalization()(decoder)\n",
        "decoder = LeakyReLU()(decoder)\n",
        "# decoder level 2\n",
        "decoder = Dense(n_inputs*2)(decoder)\n",
        "decoder = BatchNormalization()(decoder)\n",
        "decoder = LeakyReLU()(decoder)"
      ],
      "metadata": {
        "id": "7zLNn6I8EJSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = Dense(n_inputs, activation='linear')(decoder)\n",
        "# define autoencoder model\n",
        "model = Model(inputs=input_data_shape, outputs=output)\n",
        "# compile autoencoder model\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "May7nOebEJl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " model.fit(weather_input,weather_input, epochs=100, batch_size=32, verbose=2)"
      ],
      "metadata": {
        "id": "bDSNxe4eE47z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define an encoder model (without the decoder)\n",
        "encoder = Model(inputs=input_data_shape, outputs=bottleneck)\n",
        "# save the encoder to file\n",
        "encoder.save('encoder.h5')"
      ],
      "metadata": {
        "id": "czWUThhJE7Pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solpow=solpow.to_numpy().reshape(-1,1)\n",
        "encoder = load_model('encoder.h5')\n",
        "\n",
        "# encode the train data\n",
        "X_train_encode = encoder.predict(weather_input)"
      ],
      "metadata": {
        "id": "jhuvCvIWFQwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = load_model('encoder.h5')\n",
        "\n",
        "# encode the train data\n",
        "X_train_encode = encoder.predict(weather_input)"
      ],
      "metadata": {
        "id": "moGLepO3Im8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_steps = 3\n",
        "# training set\n",
        "(x_transformed1,\n",
        " y_transformed1) = lstm_data_transform(X_train_encode,solpow , num_steps=num_steps)\n",
        "assert x_transformed1.shape[0] == y_transformed1.shape[0]"
      ],
      "metadata": {
        "id": "Gste5MwfFVPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(x_transformed1, y_transformed1, test_size=0.4, random_state=42,shuffle=False)"
      ],
      "metadata": {
        "id": "XsA3YUEIFZx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs1=Input(shape=(X_train1.shape[1],X_train1.shape[2]))"
      ],
      "metadata": {
        "id": "fdfdQDOSF21B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model1(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe1_0 = Bidirectional(LSTM(32, activation='relu',return_sequences = True))(inputs1)#32\n",
        "    fe1_1 = Dropout(0.2)(fe1_0)\n",
        "    fe1_2 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(fe1_1)#16\n",
        "    fe1_3= Dropout(0.2)(fe1_2)\n",
        "    fe1_4=Bidirectional(LSTM(8, activation='relu'))(fe1_3)#8\n",
        "    out1_1=Dense(1, activation='linear')(fe1_4)\n",
        "    return Model(inputs1, out1_1)\n",
        "def get_model2(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe2_0 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(inputs1)#16,16,8\n",
        "    fe2_1 = Dropout(0.5)(fe2_0)\n",
        "    fe2_2 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(fe2_1)\n",
        "    fe2_3= Dropout(0.5)(fe2_2)\n",
        "    fe2_4=Bidirectional(LSTM(8, activation='relu'))(fe2_3)\n",
        "    out2_1=Dense(1, activation='linear')(fe2_4)\n",
        "    return Model(inputs1, out2_1)\n",
        "def get_model3(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe3_0 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(inputs1)#16,8,8\n",
        "    fe3_1 = Dropout(0.5)(fe3_0)\n",
        "    fe3_2 = Bidirectional(LSTM(8, activation='relu',return_sequences = True))(fe3_1)\n",
        "    fe3_3= Dropout(0.5)(fe3_2)\n",
        "    fe3_4=Bidirectional(LSTM(8, activation='relu'))(fe3_3)\n",
        "    out3_1=Dense(1, activation='linear')(fe3_4)\n",
        "    return Model(inputs1, out3_1)\n",
        "model1 = get_model1() \n",
        "model2 = get_model2() \n",
        "model3 = get_model3()\n",
        "y1 = model1(inputs1) \n",
        "y2 = model2(inputs1) \n",
        "y3 = model3(inputs1)\n",
        "outputs = layers.average([y1, y2, y3]) \n",
        "ensemble_model = Model(inputs=inputs1, outputs=outputs)\n",
        "ensemble_model.compile(optimizer='Adam',loss='mean_squared_error',metrics=['RootMeanSquaredError'])\n",
        "history=ensemble_model.fit(X_train1, y_train1, epochs = 200, batch_size = 64)"
      ],
      "metadata": {
        "id": "t2xAJ_P5F1PM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_en=ensemble_model.predict(X_test1)\n",
        "plt.scatter(y_en,y_test1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q1msjytCGRcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uDhkVXrxJyM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ = pd.DataFrame()\n",
        "df_['time']=[i for i in range(len(y_en))]\n",
        "df_['Actual']=y_test\n",
        "df_['Predicted']=y_en"
      ],
      "metadata": {
        "id": "0aFB8eDmF9wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(df_['time'],df_['Actual'])\n",
        "plt.plot(df_['time'],df_['Predicted'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hqm2ceUpGQpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA "
      ],
      "metadata": {
        "id": "8u45S8L-C-H8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components = 20)\n",
        "pca.fit(weather_input)\n",
        "data_pca = pca.transform(weather_input)\n",
        "data_pca = pd.DataFrame(data_pca)"
      ],
      "metadata": {
        "id": "LPHKHSQ3DbwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_pca.head()"
      ],
      "metadata": {
        "id": "5N9PD_WADrXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_steps = 3\n",
        "# training set\n",
        "(x_transformed1,\n",
        " y_transformed1) = lstm_data_transform(data_pca,solpow , num_steps=num_steps)\n",
        "assert x_transformed1.shape[0] == y_transformed1.shape[0]"
      ],
      "metadata": {
        "id": "3X0RtE8DDwKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train2, X_test2, y_train2, y_test2= train_test_split(x_transformed1, y_transformed1, test_size=0.4, random_state=42,shuffle=False)"
      ],
      "metadata": {
        "id": "S0L4GSxJD6r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model1(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe1_0 = Bidirectional(LSTM(32, activation='relu',return_sequences = True))(inputs1)#32\n",
        "    fe1_1 = Dropout(0.2)(fe1_0)\n",
        "    fe1_2 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(fe1_1)#16\n",
        "    fe1_3= Dropout(0.2)(fe1_2)\n",
        "    fe1_4=Bidirectional(LSTM(8, activation='relu'))(fe1_3)#8\n",
        "    out1_1=Dense(1, activation='linear')(fe1_4)\n",
        "    return Model(inputs1, out1_1)\n",
        "def get_model2(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe2_0 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(inputs1)#16,16,8\n",
        "    fe2_1 = Dropout(0.5)(fe2_0)\n",
        "    fe2_2 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(fe2_1)\n",
        "    fe2_3= Dropout(0.5)(fe2_2)\n",
        "    fe2_4=Bidirectional(LSTM(8, activation='relu'))(fe2_3)\n",
        "    out2_1=Dense(1, activation='linear')(fe2_4)\n",
        "    return Model(inputs1, out2_1)\n",
        "def get_model3(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe3_0 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(inputs1)#16,8,8\n",
        "    fe3_1 = Dropout(0.5)(fe3_0)\n",
        "    fe3_2 = Bidirectional(LSTM(8, activation='relu',return_sequences = True))(fe3_1)\n",
        "    fe3_3= Dropout(0.5)(fe3_2)\n",
        "    fe3_4=Bidirectional(LSTM(8, activation='relu'))(fe3_3)\n",
        "    out3_1=Dense(1, activation='linear')(fe3_4)\n",
        "    return Model(inputs1, out3_1)\n",
        "model1 = get_model1() \n",
        "model2 = get_model2() \n",
        "model3 = get_model3()\n",
        "y1 = model1(inputs1) \n",
        "y2 = model2(inputs1) \n",
        "y3 = model3(inputs1)\n",
        "outputs = layers.average([y1, y2, y3]) \n",
        "ensemble_model = Model(inputs=inputs1, outputs=outputs)\n",
        "ensemble_model.compile(optimizer='Adam',loss='mean_squared_error',metrics=['RootMeanSquaredError'])\n",
        "history=ensemble_model.fit(X_train2, y_train2, epochs = 200, batch_size = 64)"
      ],
      "metadata": {
        "id": "fPBzdko0EGyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_en=ensemble_model.predict(X_test2)\n",
        "plt.scatter(y_en,y_test2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y6bxKrR2FDJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ = pd.DataFrame()\n",
        "df_['time']=[i for i in range(len(y_en))]\n",
        "df_['Actual']=y_test2\n",
        "df_['Predicted']=y_en"
      ],
      "metadata": {
        "id": "8SGphIb6GLGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(df_['time'],df_['Actual'])\n",
        "plt.plot(df_['time'],df_['Predicted'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "je-XiD7zGVsj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}