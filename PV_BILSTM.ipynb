{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPF62+EsWyowIN8OzXdO+Pz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIPANJAN001/Dipanjanpatra/blob/master/PV_BILSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ALL IMPORTS"
      ],
      "metadata": {
        "id": "qrFqdSAWKtt0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc_yMJDxJ3hB",
        "outputId": "5e4b57fa-d077-4825-bf98-d7e76a937522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Boruta\n",
            "  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from Boruta) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from Boruta) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from Boruta) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.17.1->Boruta) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.17.1->Boruta) (1.2.0)\n",
            "Installing collected packages: Boruta\n",
            "Successfully installed Boruta-0.3\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install Boruta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from boruta import BorutaPy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import concatenate\n",
        "from keras import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Bidirectional\n",
        "from keras import layers\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input\n",
        "from sklearn.decomposition import PCA "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TIME SERIES TO SUPERVISED"
      ],
      "metadata": {
        "id": "xyVDCaaqLB9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_data_transform(x_data, y_data, num_steps):\n",
        "    \"\"\" Changes data to the format for LSTM training \n",
        "for sliding window approach \"\"\"\n",
        "    # Prepare the list for the transformed data\n",
        "    X, y = list(), list()\n",
        "    # Loop of the entire data set\n",
        "    for i in range(x_data.shape[0]):\n",
        "        # compute a new (sliding window) index\n",
        "        end_ix = i + num_steps\n",
        "        # if index is larger than the size of the dataset, we stop\n",
        "        if end_ix >= x_data.shape[0]:\n",
        "            break\n",
        "        # Get a sequence of data for x\n",
        "        seq_X = x_data[i:end_ix]\n",
        "        # Get only the last element of the sequency for y\n",
        "        seq_y = y_data[end_ix]\n",
        "        # Append the list with sequencies\n",
        "        X.append(seq_X)\n",
        "        y.append(seq_y)\n",
        "    # Make final arrays\n",
        "    x_array = np.array(X)\n",
        "    y_array = np.array(y)\n",
        "    return x_array, y_array"
      ],
      "metadata": {
        "id": "BV58chSULAuu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATA LOADING"
      ],
      "metadata": {
        "id": "gdsH3kOPK3TU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_excel(\"/content/pv_04.xlsx\")\n",
        "weather_input1=df.drop('power_normed',axis=1)\n",
        "weather_input=weather_input1.drop('time_idx',axis=1)\n",
        "solpow=df['power_normed']"
      ],
      "metadata": {
        "id": "s8Nk-AywKkBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### INPUTS"
      ],
      "metadata": {
        "id": "sqzigqyELpVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_steps = 3\n",
        "EPOCH=100\n",
        "VAL_SPLIT=0.2\n",
        "BATCH_SIZE=64"
      ],
      "metadata": {
        "id": "5KfNHeN1LrYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BORUTA FEATURE SELECTION"
      ],
      "metadata": {
        "id": "jwBH43VjLOfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestRegressor(random_state=1, n_estimators=1000, max_depth=5)\n",
        "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, random_state=1)\n",
        "boruta_selector.fit(np.array(weather_input), np.array(solpow)) "
      ],
      "metadata": {
        "id": "gZq74EiBLJvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_important_train = boruta_selector.transform(np.array(weather_input))\n",
        "# training set\n",
        "(x_transformed_train,\n",
        " y_transformed_train) = lstm_data_transform(X_important_train,solpow , num_steps=num_steps)\n",
        "assert x_transformed_train.shape[0] == y_transformed_train.shape[0]\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(x_transformed_train,y_transformed_train,test_size=0.4, random_state=42,shuffle=False)\n",
        "#X_train_,X_val,y_train_,y_val=train_test_split(X_train,y_train,test_size=0.2, random_state=42,shuffle=False)"
      ],
      "metadata": {
        "id": "DnvGnveYLUDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs1 = Input(shape=(X_train1.shape[1],X_train1.shape[2]))"
      ],
      "metadata": {
        "id": "CG6_R4_eLtgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model11(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe1_0 = Bidirectional(LSTM(32, activation='relu',return_sequences = True))(inputs1)#32\n",
        "    fe1_1 = Dropout(0.5)(fe1_0)\n",
        "    fe1_2 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(fe1_1)#16\n",
        "    fe1_3= Dropout(0.5)(fe1_2)\n",
        "    fe1_4=Bidirectional(LSTM(8, activation='relu'))(fe1_3)#8\n",
        "    out1_1=Dense(1, activation='linear')(fe1_4)\n",
        "    return Model(inputs1, out1_1)\n",
        "def get_model21(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe2_0 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(inputs1)#16,16,8\n",
        "    fe2_1 = Dropout(0.5)(fe2_0)\n",
        "    fe2_2 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(fe2_1)\n",
        "    fe2_3= Dropout(0.5)(fe2_2)\n",
        "    fe2_4=Bidirectional(LSTM(8, activation='relu'))(fe2_3)\n",
        "    out2_1=Dense(1, activation='linear')(fe2_4)\n",
        "    return Model(inputs1, out2_1)\n",
        "def get_model31(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe3_0 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(inputs1)#16,8,8\n",
        "    fe3_1 = Dropout(0.5)(fe3_0)\n",
        "    fe3_2 = Bidirectional(LSTM(8, activation='relu',return_sequences = True))(fe3_1)\n",
        "    fe3_3= Dropout(0.5)(fe3_2)\n",
        "    fe3_4=Bidirectional(LSTM(8, activation='relu'))(fe3_3)\n",
        "    out3_1=Dense(1, activation='linear')(fe3_4)\n",
        "    return Model(inputs1, out3_1)\n",
        "model1 = get_model11() \n",
        "model2 = get_model21() \n",
        "model3 = get_model31()\n",
        "y1 = model1(inputs1) \n",
        "y2 = model2(inputs1) \n",
        "y3 = model3(inputs1)\n",
        "outputs = layers.average([y1, y2, y3]) \n",
        "ensemble_model1= Model(inputs=inputs1, outputs=outputs)\n",
        "ensemble_model1.compile(optimizer='Adam',loss='mean_squared_error',metrics=['RootMeanSquaredError'])\n",
        "history=ensemble_model1.fit(X_train1, y_train1, epochs = EPOCH,validation_split=VAL_SPLIT,batch_size = BATCH_SIZE)"
      ],
      "metadata": {
        "id": "70DILFa4L6Y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TRAINING AND VALIDATIUON ERROR PLOT"
      ],
      "metadata": {
        "id": "6eXXdQBUMf6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='val')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ue_BFfXJMfI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PREDICTION"
      ],
      "metadata": {
        "id": "_Oa6V-zbMrVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y1=ensemble_model1.predict(X_test1)\n",
        "plt.scatter(y1,y_test1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B6tBkAE3MoDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ = pd.DataFrame()\n",
        "df_['time']=[i for i in range(len(y1))]\n",
        "df_['Actual']=y_test1\n",
        "df_['Predicted']=y1\n",
        "plt.plot(df_['time'],df_['Actual'])\n",
        "\n",
        "plt.plot(df_['time'],df_['Predicted'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QQE5ynM-Mzek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AUTOENCODER+BILSTM"
      ],
      "metadata": {
        "id": "q0QWuBB0NVe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_inputs=weather_input.shape[1]"
      ],
      "metadata": {
        "id": "TBbud0qlNUXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_shape= Input(shape=(n_inputs,))\n",
        "# encoder level 1\n",
        "encoder= Dense(n_inputs*2)(input_data_shape)\n",
        "encoder = BatchNormalization()(encoder)\n",
        "encoder= LeakyReLU()(encoder)\n",
        "# encoder level 2\n",
        "encoder= Dense(n_inputs)(encoder)\n",
        "encoder= BatchNormalization()(encoder)\n",
        "encoder= LeakyReLU()(encoder)\n",
        "# bottleneck\n",
        "#n_bottleneck = round(float(n_inputs) / 2.0)\n",
        "n_bottleneck = 20\n",
        "bottleneck = Dense(n_bottleneck)(encoder)\n",
        "# define decoder, level 1\n",
        "decoder = Dense(n_inputs)(bottleneck)\n",
        "decoder = BatchNormalization()(decoder)\n",
        "decoder = LeakyReLU()(decoder)\n",
        "# decoder level 2\n",
        "decoder = Dense(n_inputs*2)(decoder)\n",
        "decoder = BatchNormalization()(decoder)\n",
        "decoder = LeakyReLU()(decoder)"
      ],
      "metadata": {
        "id": "CuDuGgC7Nf3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = Dense(n_inputs, activation='linear')(decoder)\n",
        "# define autoencoder model\n",
        "model = Model(inputs=input_data_shape, outputs=output)\n",
        "# compile autoencoder model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(weather_input,weather_input, epochs=100, batch_size=32, verbose=2)"
      ],
      "metadata": {
        "id": "tpU4Qj87NiRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o3cNAdclOoSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Model(inputs=input_data_shape, outputs=bottleneck)\n",
        "# save the encoder to file\n",
        "encoder.save('encoder.h5')\n",
        "encoder = load_model('encoder.h5')\n",
        "\n",
        "# encode the train data\n",
        "X_train_encode = encoder.predict(weather_input)"
      ],
      "metadata": {
        "id": "6MAfI5RmNoH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_transformed2,\n",
        " y_transformed2) = lstm_data_transform(X_train_encode,solpow , num_steps=num_steps)\n",
        "assert x_transformed2.shape[0] == y_transformed2.shape[0]"
      ],
      "metadata": {
        "id": "_VytBRNmNt28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_transformed2, y_transformed2, test_size=0.4, random_state=42,shuffle=False)"
      ],
      "metadata": {
        "id": "B2AH4sOlNxYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs2=Input(shape=(X_train2.shape[1],X_train2.shape[2]))"
      ],
      "metadata": {
        "id": "2NW-GRZrN2GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model12(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe1_0 = Bidirectional(LSTM(32, activation='relu',return_sequences = True))(inputs1)#32\n",
        "    fe1_1 = Dropout(0.2)(fe1_0)\n",
        "    fe1_2 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(fe1_1)#16\n",
        "    fe1_3= Dropout(0.2)(fe1_2)\n",
        "    fe1_4=Bidirectional(LSTM(8, activation='relu'))(fe1_3)#8\n",
        "    out1_1=Dense(1, activation='linear')(fe1_4)\n",
        "    return Model(inputs1, out1_1)\n",
        "def get_model22(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe2_0 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(inputs1)#16,16,8\n",
        "    fe2_1 = Dropout(0.5)(fe2_0)\n",
        "    fe2_2 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(fe2_1)\n",
        "    fe2_3= Dropout(0.5)(fe2_2)\n",
        "    fe2_4=Bidirectional(LSTM(8, activation='relu'))(fe2_3)\n",
        "    out2_1=Dense(1, activation='linear')(fe2_4)\n",
        "    return Model(inputs1, out2_1)\n",
        "def get_model32(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe3_0 = Bidirectional(LSTM(16, activation='relu',return_sequences = True))(inputs1)#16,8,8\n",
        "    fe3_1 = Dropout(0.5)(fe3_0)\n",
        "    fe3_2 = Bidirectional(LSTM(8, activation='relu',return_sequences = True))(fe3_1)\n",
        "    fe3_3= Dropout(0.5)(fe3_2)\n",
        "    fe3_4=Bidirectional(LSTM(8, activation='relu'))(fe3_3)\n",
        "    out3_1=Dense(1, activation='linear')(fe3_4)\n",
        "    return Model(inputs1, out3_1)\n",
        "model1 = get_model12() \n",
        "model2 = get_model22() \n",
        "model3 = get_model32()\n",
        "y1 = model1(inputs2) \n",
        "y2 = model2(inputs2) \n",
        "y3 = model3(inputs2)\n",
        "outputs = layers.average([y1, y2, y3]) \n",
        "ensemble_model2 = Model(inputs=inputs1, outputs=outputs)\n",
        "ensemble_model2.compile(optimizer='Adam',loss='mean_squared_error',metrics=['RootMeanSquaredError'])\n",
        "history=ensemble_model2.fit(X_train2, y_train2, epochs = EPOCH,validation_split=VAL_SPLIT,batch_size = BATCH_SIZE)"
      ],
      "metadata": {
        "id": "Q_1wY_U9OAoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ocfiXMuKOOXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y2=ensemble_model2.predict(X_test1)\n",
        "plt.scatter(y2,y_test2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A0HYDwxEOVvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ = pd.DataFrame()\n",
        "df_['time']=[i for i in range(len(y2))]\n",
        "df_['Actual']=y_test2\n",
        "df_['Predicted']=y2\n",
        "plt.plot(df_['time'],df_['Actual'])\n",
        "\n",
        "plt.plot(df_['time'],df_['Predicted'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AMQbq37JOsz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PCA"
      ],
      "metadata": {
        "id": "n8zNlAi_PHN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components = 16)\n",
        "pca.fit(weather_input)\n",
        "data_pca = pca.transform(weather_input)\n",
        "data_pca = pd.DataFrame(data_pca)"
      ],
      "metadata": {
        "id": "sIboN1w3PDcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_transformed3,\n",
        " y_transformed3) = lstm_data_transform(data_pca,solpow , num_steps=num_steps)\n",
        "assert x_transformed3.shape[0] == y_transformed3.shape[0]"
      ],
      "metadata": {
        "id": "UskGO0H3PTrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train3, X_test3, y_train3, y_test3= train_test_split(x_transformed3, y_transformed3, test_size=0.4, random_state=42,shuffle=False)"
      ],
      "metadata": {
        "id": "ZOlFVVnuPhiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs3=Input(shape=(X_train3.shape[1],X_train3.shape[2]))"
      ],
      "metadata": {
        "id": "JhJT6BKjPxG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model13(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe1_0 = LSTM(32, activation='relu',return_sequences = True)(inputs1)#32\n",
        "    fe1_1 = Dropout(0.2)(fe1_0)\n",
        "    fe1_2 = LSTM(16, activation='relu',return_sequences = True)(fe1_1)#16\n",
        "    fe1_3= Dropout(0.2)(fe1_2)\n",
        "    fe1_4=LSTM(8, activation='relu')(fe1_3)#8\n",
        "    out1_1=Dense(1, activation='linear')(fe1_4)\n",
        "    return Model(inputs1, out1_1)\n",
        "def get_model23(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe2_0 = LSTM(16, activation='relu',return_sequences = True)(inputs1)#16,16,8\n",
        "    fe2_1 = Dropout(0.5)(fe2_0)\n",
        "    fe2_2 = LSTM(16, activation='relu',return_sequences = True)(fe2_1)\n",
        "    fe2_3= Dropout(0.5)(fe2_2)\n",
        "    fe2_4=LSTM(8, activation='relu')(fe2_3)\n",
        "    out2_1=Dense(1, activation='linear')(fe2_4)\n",
        "    return Model(inputs1, out2_1)\n",
        "def get_model33(): \n",
        "    #inputs1 = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "    fe3_0 = LSTM(16, activation='relu',return_sequences = True)(inputs1)#16,8,8\n",
        "    fe3_1 = Dropout(0.5)(fe3_0)\n",
        "    fe3_2 = LSTM(8, activation='relu',return_sequences = True)(fe3_1)\n",
        "    fe3_3= Dropout(0.5)(fe3_2)\n",
        "    fe3_4=LSTM(8, activation='relu')(fe3_3)\n",
        "    out3_1=Dense(1, activation='linear')(fe3_4)\n",
        "    return Model(inputs1, out3_1)\n",
        "model1 = get_model13() \n",
        "model2 = get_model23() \n",
        "model3 = get_model33()\n",
        "y1 = model1(inputs3) \n",
        "y2 = model2(inputs3) \n",
        "y3 = model3(inputs3)\n",
        "outputs = layers.average([y1, y2, y3]) \n",
        "ensemble_model3 = Model(inputs=inputs1, outputs=outputs)\n",
        "ensemble_model3.compile(optimizer='Adam',loss='mean_squared_error',metrics=['RootMeanSquaredError'])\n",
        "history=ensemble_model3.fit(X_train3, y_train3, epochs = EPOCH,validation_split=VAL_SPLIT,batch_size = BATCH_SIZE)"
      ],
      "metadata": {
        "id": "PSmL5oyRPznt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y3=ensemble_model3.predict(X_test2)\n",
        "plt.scatter(y3,y_test3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YERZ7jFIQCCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ = pd.DataFrame()\n",
        "df_['time']=[i for i in range(len(y3))]\n",
        "df_['Actual']=y_test3"
      ],
      "metadata": {
        "id": "MIzdKG8cQLFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(df_['time'],df_['Actual'])\n",
        "plt.plot(df_['time'],df_['Predicted'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qEd4biSUQRK1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}